# NZ Building Code Web Scraping RAG System Implementation

## Objective
Create a web scraping system to automatically collect, process, and index official New Zealand building code documents for accurate RAG-based property analysis.

## Target Data Sources

### 1. MBIE Building.govt.nz Resources
**Primary URLs to scrape:**
- `https://www.building.govt.nz/building-code-compliance/building-consent/work-that-doesnt-need-consent/`
- `https://www.building.govt.nz/building-code-compliance/building-consent/exempt-building-work/`
- `https://www.building.govt.nz/assets/Uploads/building-code-compliance/building-consent/exempt-building-work/exempt-building-work-guidance.pdf`

**Scraping Requirements:**
- Extract all PDF documents linked from these pages
- Scrape HTML content including tables, lists, and structured data
- Follow pagination and sub-category links
- Extract building code references (B1, E2, etc.)
- Capture consent exemption criteria and conditions

### 2. Legislation.govt.nz - Schedule 1
**Primary URL:**
- `https://www.legislation.govt.nz/act/public/2004/0072/latest/DLM307529.html` (Building Act 2004 - Schedule 1)

**Scraping Requirements:**
- Extract complete Schedule 1 text with all subsections
- Maintain hierarchical structure (sections, subsections, clauses)
- Preserve legal formatting and numbering
- Extract cross-references to other acts/regulations

### 3. Council-Specific Documents
**Target Councils:**
- Auckland Council: `https://www.aucklandcouncil.govt.nz/building-and-consents/`
- Wellington City: `https://wellington.govt.nz/property-rates-and-building/building-consents/`
- Christchurch City: `https://www.ccc.govt.nz/consents-and-licences/building-consents/`

**Scraping Requirements:**
- Extract council-specific exemptions and variations
- Scrape zoning-related building rules
- Capture local interpretation guidelines
- Extract contact information and process details

## Technical Implementation Requirements

### 1. Web Scraping Framework
```python
# Suggested libraries and approach
import requests
import beautifulsoup4
import pdfplumber  # For PDF extraction
import scrapy  # For complex scraping workflows
import selenium  # For JavaScript-heavy pages

# Key features needed:
- Robust error handling and retry logic
- Rate limiting to respect government servers
- User-agent rotation to avoid blocking
- Session management for multi-page workflows
```

### 2. Data Processing Pipeline
**Document Processing:**
- PDF text extraction with layout preservation
- HTML content cleaning and normalization
- Structured data extraction (tables, lists, forms)
- Metadata extraction (document dates, versions, authorities)

**Content Indexing:**
- Create embeddings for semantic search
- Tag documents by type (exemptions, codes, council-specific)
- Index by building work categories
- Cross-reference related documents

### 3. Data Storage Structure
```
building_documents/
├── mbie/
│   ├── exempt_work/
│   ├── building_codes/
│   └── guidance_documents/
├── legislation/
│   ├── building_act/
│   └── regulations/
└── councils/
    ├── auckland/
    ├── wellington/
    └── christchurch/
```

### 4. Update Mechanism
- Schedule regular scraping (weekly/monthly)
- Document version tracking
- Change detection and alerts
- Backup and rollback capabilities

## RAG Integration Points

### 1. Query Processing
When user asks about building consent requirements:
- Search indexed exemption documents
- Cross-reference Schedule 1 provisions
- Check council-specific variations
- Provide source citations with URLs

### 2. Response Enhancement
- Include specific regulation numbers
- Quote relevant clauses with proper attribution
- Provide links to original government sources
- Flag when council approval may still be needed

### 3. Accuracy Validation
- Cross-reference multiple sources
- Highlight conflicting information
- Include document dates and versions
- Provide confidence scores for responses

## Implementation Steps

### Phase 1: Core Scraping Setup
1. Set up scraping infrastructure with proper rate limiting
2. Implement PDF and HTML content extraction
3. Create document storage and indexing system
4. Test with small subset of documents

### Phase 2: Comprehensive Data Collection
1. Scrape all MBIE building guidance documents
2. Extract complete Schedule 1 from legislation.govt.nz
3. Collect major council building guidance
4. Process and index all collected documents

### Phase 3: RAG Integration
1. Integrate scraped data with existing RAG system
2. Update query processing to use official sources
3. Implement proper citation and source attribution
4. Test accuracy against known building scenarios

### Phase 4: Maintenance & Updates
1. Set up automated update schedules
2. Implement change detection and alerts
3. Create admin interface for manual updates
4. Monitor system performance and accuracy

## Legal and Technical Considerations

### Compliance
- Respect robots.txt files on government sites
- Implement reasonable rate limiting
- Use appropriate user-agent strings
- Cache responsibly to minimize server load

### Data Quality
- Validate extracted content against originals
- Handle document formatting inconsistencies
- Maintain document provenance and dates
- Flag when documents may be outdated

### Error Handling
- Graceful handling of website changes
- Fallback to cached versions when sites unavailable
- Clear error messages when data is incomplete
- Regular health checks on data sources

## Expected Outcomes

After implementation, your RAG system should be able to provide:
- Accurate citations to specific Building Act clauses
- Direct quotes from MBIE exemption guidance
- Council-specific variations and requirements
- Up-to-date regulatory information with proper attribution

This approach eliminates the need for paid APIs while ensuring your system provides authoritative, properly sourced New Zealand building code information.